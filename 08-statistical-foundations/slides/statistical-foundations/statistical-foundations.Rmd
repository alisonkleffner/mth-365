---
title: "DSC365: Introduction to Data Science"
author: "Statistical Foundations"
date: "February 26, 2026"
output: 
  xaringan::moon_reader:
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r echo=FALSE, message=FALSE, warning = FALSE}
library(tidyverse)
library(knitr)
library(RColorBrewer)
library(mosaic)
library(infer)


hook_output = knit_hooks$get('output')
knit_hooks$set(output = function(x, options) {
  # this hook is used only when the linewidth option is not NULL
  if (!is.null(n <- options$linewidth)) {
    x = xfun::split_lines(x)
    # any lines wider than n should be wrapped
    if (any(nchar(x) > n)) x = strwrap(x, width = n)
    x = paste(x, collapse = '\n')
  }
  hook_output(x, options)
})

```

### Announcements

**Lab 4**

- Due Tuesday March 3rd at 11:59 pm in Blueline

**Quiz 2**

- Last 30 minutes of class Thursday March 5th 
- Topics: Data Communication and Statistical Foundations/Linear Models

**Lab 5**: work day in class on Thursday March 5th

- Due Tuesday March 24th at 11:59 pm in Blueline

**Mini Project 2**

- Due Thursday March 19th at 11:59 in Blueline



---
### Isn't this data science?

- Statistics: 

<br>
<br>
<br>
<br>

- Data science:  


---
### Samples and Population

In statistics we are interested in a **population** of cases/people/objects.
- Often this population is too large to collect data on, so we take **samples** from the larger population.

Statistical methodology assumes that the cases are drawn from a much larger set of potential cases

---
### Uncertainty

What do we mean by uncertainty?

- Roughly equivalent to the notion of repeatability. 

<br>
<br>
<br>
<br>
<br>

Why are Statisticians Always Uncertain?
 


---
### Example: Setting travel policy through sampling

**Example**: You’ve been asked to develop a travel policy for business travelers going from New York City to Chicago. Assume that the `nycflights13` data set represents the complete population of flights.


**Clean Data:** filter all the flights going to Chicago and with a non-NA value of arrival delay time.

```{r}
library(nycflights13)
Chicago <- flights %>%
  filter(dest %in% c('ORD', 'MDW'), !is.na(arr_delay))

mean(Chicago$arr_delay) # population value
```

---
### Let's find a Sample (n=100)!

How long of a delay should we expect based on the sample?

```{r}
set.seed(365)
Sample100 <- Chicago %>% sample_n(size=100)
```


```{r}
Sample100 %>% summarize(min=min(arr_delay),
                        q05=quantile(arr_delay, 0.05),
                        mean=mean(arr_delay),
                        median=median(arr_delay),
                        max=max(arr_delay), 
                        q95=quantile(arr_delay, 0.95),
                        sd=sd(arr_delay))
```

---
### What constitutes an “unacceptable” delay?

How about an one and forty-five minuted delay (105 minutes)?

```{r}
Chicago %>% mutate(less105 = arr_delay<=105) %>% 
  group_by(less105) %>% 
  count() %>%
  mutate(pct = n / nrow(Chicago))
```

---
### Take Another sample


```{r}
set.seed(10)
Sample100_2 <- Chicago %>% sample_n(size=100)

Sample100_2 %>% summarize(mean=mean(arr_delay),
            min=min(arr_delay),
            max=max(arr_delay), 
            sd=sd(arr_delay))
```


The sample mean is now 9.64. How does this compare to the previous sample? 

---
### Sample Statistics 

Statistic: A quantity computed from values in a sample to represent some characteristics

Examples:

+ Mean $(\bar{x})$
+ Proportion $(\hat{p})$
+ Standard Deviation $(s)$

---
### Sampling Distributions

Sample statistics depend completely on the data. Different samples of data will have different sample statistics!

We need to figure out the reliability of a sample statistic from the sample itself. 
 

---
### Creating a Sampling Distribution

We could run the previous code multiple times to obtain our different samples or, we could speed it up:

```{r}
n <- 100
num_trials <- 500
chi_25_means <- 1:num_trials %>% 
    map_dfr(~Chicago %>% slice_sample(n = n) %>% 
        summarize(mean_arr_delay = mean(arr_delay))) %>% 
  mutate(n = n)

head(chi_25_means)
```

---
### Creating a Sampling Distribution

```{r}
favstats(~mean_arr_delay, data=chi_25_means) #mosaic library
```

```{r, fig.height=4.5, fig.width=8, fig.align='center', fig.alt="Density plot depicting the approximate sampling distribution of the sample mean. It is an approximate bell-shaped curve."}
ggplot(chi_25_means, aes(x=mean_arr_delay)) + 
  geom_density(fill='turquoise', alpha=0.5) + 
  labs(x='Approximate Sampling Distribution of Sample Mean')
```

---
### What does the Sampling Distribution tells us?

- Where is the sampling distribution centered? 

<br>
<br>
<br>
<br>
<br>

- How spread out is the sampling distribution? 

---
### Discuss Reliability: Standard Error

**Standard error**: It describes the width of the sampling distribution.

<br>
<br>
<br>
<br>

Example: What’s the standard error of the sample mean?

```{r}
favstats(~arr_delay, data=Sample100)
```

```{r}
favstats(~mean_arr_delay, data=chi_25_means)
```


---
### How does n Affect the Sampling Distribution?

```{r means, message=FALSE, warning=FALSE, cache=TRUE}
Means50 <- do(1000)*(Chicago %>% sample_n(size=50) %>% 
                       summarize(mean=mean(arr_delay)))
Means100 <- do(1000)*(Chicago %>% sample_n(size=100) %>% 
                        summarize(mean=mean(arr_delay)))
Means500 <- do(1000)*(Chicago %>% sample_n(size=500) %>% 
                        summarize(mean=mean(arr_delay)))
```

```{r, message=FALSE, warning=FALSE, fig.align='center', fig.height=4, fig.width=8, echo=FALSE}
Means <- rbind(Means50 %>% mutate(n=50),
               Means100 %>% mutate(n=100),
               Means500 %>% mutate(n=500))
```

```{r, message=FALSE, warning=FALSE, fig.align='center', fig.height=4, fig.width=8, echo=FALSE, fig.alt="This figure shows the impact of sample size on sampling distributions. As the sample size increases from 50 to 500, the width or variability of the sampling distribution becomes narrower."}
ggplot(dat=Means, aes(x=mean)) + 
  geom_density(aes(fill=as.factor(n))) + 
  facet_grid(~n)+xlab('Sample means') + guides(fill=FALSE)
```


---
### Bootstraping

In the last example, we had access to the population data and so we could find the sampling distribution by repeatedly sampling from the population. 

**Bootstrap:** allows us to approximate the sampling distribution even though we do not have the population.



---
### Bootstraping


---
### Bootstraping: Let's take a small sample (n=3)

```{r}
f3 <- Chicago %>% sample_n(size=3) %>% dplyr::select(year,month,day)
```

```{r, echo=FALSE}
f3 
```


.pull-left[
First Resample: 
```{r}
f3 %>% slice_sample(n= 3, 
               replace = TRUE)
```
].pull-right[
Second Resample: 
```{r}
f3 %>% slice_sample(n= 3, 
               replace = TRUE)
```
]

---
### Bootstrapping: Bigger Sample

```{r, fig.height=4.5, fig.width=8, fig.align='center', fig.alt="Density plot of the bootstraped distribution for sample means. This is approximately normal and is similar in appearance to the sampling distribution."}

Bootstrap_Means <- Sample100 %>% 
  specify(response = arr_delay) %>%
  generate(reps = 500, type = "bootstrap") %>%
  calculate(stat = "mean")

ggplot(Bootstrap_Means, aes(x=stat))+
  geom_density(fill='turquoise', alpha=0.5)+labs(x='Bootstrap Means')

```

---
### Bootstrapping: Bigger Sample


Bootstrap Sample:
```{r}
favstats(~stat, data=Bootstrap_Means)
```

Sampling Distribution:
```{r}
favstats(~mean_arr_delay, data=chi_25_means)
```

---
### Hypothesis Tests and its Perils

.center[
Used to check if a claim about the population is true]


1). Write out your hypotheses for testing

- Nnull hypothesis $(H_0)$: the status quo ("there is nothign going on")
- Alternative hypothesis $(H_A)$: that represents the research question, i.e. what we’re testing for
  - Can be one-sided $(<,>)$ or two-sided $(\neq)$

2/3). Calculate a test-statistic/p-value under assumption $(H_0)$ is true

<br>
<br>
<br>

4). If the test results suggest that the data do not provide convincing evidence for the alternative hypothesis, stick with the null hypothesis
  - If they do, then reject the null hypothesis in favor of the alternative


---
### Example: Lee Corso Head Gear Picks

Lee Corso is a football analyst/broadcaster known for his “headgear” picks on ESPNs College GameDay until his recent retirement. But the real question is, does he know what he is talking about? We randomly selected 100 games and found he correctly picked 62 teams correctly out of 100 games (62%)

```{r, echo=FALSE, fig.align='center', out.width="35%", fig.alt = "Image of Lee Corse wearing a corn hat after he picked Nebraska to win."}

knitr::include_graphics("~/Documents/Classes/MTH365/mth-365/08-statistical-foundations/slides/images/corso.png")

```





---
### Null Distribution

- If he was just guessing, we'd expect him to correctly pick the correct team about half of the time
  + Hence we want to simulate a random process, assuming the null hypothesis is true, called a **Null Distribution**

<br>

```{r, echo = FALSE, fig.align='center', fig.width=10, fig.height=5, fig.alt="Histogram of a simulated null distribution that looks approximately normal."}

set.seed(4)
patriots_sim = do(10000)*nflip(100)

ggplot(patriots_sim) + 
  geom_histogram(aes(x=nflip), binwidth=1)
```


---
### Lee Corso: P-value

**p-value:**

<br>
<br>

```{r, echo = FALSE, fig.align='center', fig.width=10, fig.height=5, fig.alt="Same histrogram as the previous slide, however now a line is drawn at the value of the calculated test statistic. The shaded region on the plot represents the p-value."}

#sum(patriots_sim >= 19)

patriots_sim <- patriots_sim %>% mutate(pvalue = ifelse(nflip < 62, "less", "greater"))

ggplot(patriots_sim) + 
  geom_histogram(aes(x=nflip, fill = pvalue), binwidth=1) +
  geom_vline(xintercept = 61.5) + 
  geom_text(x=64, y=500, label='P(>= 62 Wins) = 0.0111', colour='black', size=5) + theme(legend.position="none")


```


---
### Making Conclusions

We often use 5% as the cutoff for whether the p-value is low enough that the data are unlikely to have come from the null model. This cutoff value is called the significance level, $\alpha$.

- If p-value < $\alpha$ , reject $H_0$ in favor of $H_A$: The data provide convincing evidence for the alternative hypothesis.

- If p-value > $\alpha$, fail to reject $H_0$ in favor of $H_A$: The data do not provide convincing evidence for the alternative hypothesis.




