---
title: 'Week 2 Lecture: Hello R!'
author: 'MTH 365: Basic R and R Markdown'
date: "August 22, 2023"
output:
  pdf_document: default
---

## Announcement

## Getting started

We have briefly discussed R, Rstudio and RMarkdown. This week, we will continue to build some basic fluency in R. Today we begin with the fundamental building blocks of R and RStudio: the interface, reading in data, and basic commands.

Each week, I'll provide you with an RMarkdown document (like this) containing the code for in-class examples. Here's what I suggest:

1. Take notes in this RMarkdown document. You can write anywhere in the white spaces.
2. Run the code on your machines as we run it in class. The code "chunks" are in grey.
3. After class, "Knit" this document into an HTML, PDF, or Word (your choice) file to use later.

Of course, you can take notes however you choose! However, this isn't one of those courses that you can just "follow along" during. Actively taking notes and running code is the best way to learn data science!

## Packages

Today we will work with two packages: `datasauRus` which contains the data set, and `tidyverse` which is a collection of packages for doing data analysis in a "tidy" way.

Install these packages by running the following code. You can do that in a R Markdown document by clicking the green arrow "Run" button. You should have installed `tidyverse` already last week.

```{r}
#install.packages("tidyverse")
#install.packages("datasauRus")
```

Another way to install the package: Click on the "Packages" tab, and click the Install button. Type the package name and click install.

You only need to do this one time! Once a package is installed on your computer, you don't need to install it again. So, make sure the code chunk is commented out before your run the whole document.

Now that the packages are installed, you'll need to load them to work with the functions and data within. You can load packages using the `library()` command.

```{r, message=FALSE}
library(tidyverse) 
library(datasauRus)
```

When creating your own `R Markdown` document, I recommend having a code chunk at the beginning with all the packages you plan on using. 

## Data

In data science, of course, we will work with data. Then, what is data? In fact, data can have multiple formats. Numbers, categories, and even text and videos are all forms of data. However, in order to analyze the data in an easy way, we usually organize the data into a data frame. For example, this is a data frame, it looks like a matrix:

```{r}
data("datasaurus_dozen")

# show the first 6 rows of the data
head(datasaurus_dozen)

```
In a data frame, each row is an *observation* and each column is a *variable*. Each observation should have the same number of variables. If not, we have a *list*, which we will not cover in this course. 

In the last class, we went through a couple of ways to extract certain variable/observation from the data frame in basic R. The data frame you'll work with today is called `datasaurus_dozen` and it's in the `datasauRus` package. Actually, this single data frame contains 13 datasets. The different datasets are marked by the `dataset` variable.

- If it's confusing that the data frame is called `datasaurus_dozen` when it contains 13 datasets, you're not alone! Have you heard of a baker's dozen?

```{r, eval=FALSE}
#Extract the second observation in the data

datasaurus_dozen[2,]

#Extract the second variable in the data
datasaurus_dozen[,2] #OR
datasaurus_dozen$x

```

Once you extract the information, sometimes you need to save it for the later use. You can assign the extracted information to a new variable. 

```{r}
x_value <- datasaurus_dozen$x
```

If you run the above line, nothing will show as the result but if you check the environment, we now have a new variable called *x_value* which you can use later. For example, you can print it out below. 

```{r, eval=FALSE}
x_value
```

### Try it for yourself

1. Extract the y variable from the data and assign it to a new variable

```{r}
y_value <- datasaurus_dozen$y
```

2. Extract the 100th observation from the data, assign it to a new variable and print it out. (Can I name the new variable as 100obs? or does it have to be obs100? )

```{r}

obs100 <- datasaurus_dozen[100,]
obs100

```

## Basic data summary

Another piece of information people want to know is how many rows and how many columns does the `datasaurus_dozen` file have? What are the variables included in the data frame? To answer those questions, we can do:

```{r}
# Show the row number and column number
dim(datasaurus_dozen)

# OR
nrow(datasaurus_dozen)
ncol(datasaurus_dozen)

# Show the variable list

glimpse(datasaurus_dozen)

str(datasaurus_dozen)

# basic summary of whole dataset
summary(datasaurus_dozen)

```

Let's take a look at what these datasets are. To do so we can make a *frequency table* of the dataset variable:

```{r}

count(datasaurus_dozen, dataset)

#count() lets you quickly count the unique values of one or more variables: 

```

## Demo: summary statistics and data visualization

Note: we will go over the functions and concepts in this section again in the next two weeks. Today's goal is just to show you: 

(1) why data visualization is important and 

(2) how summary statistics alone can be misleading. 

The original Datasaurus (`dino`) was created by Alberto Cairo in [this blog post](http://www.thefunctionalart.com/2016/08/download-datasaurus-never-trust-summary.html). The other Dozen were generated using simulated annealing and the process is described in the paper *Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing* by Justin Matejka and George Fitzmaurice. In the paper, the authors simulate a variety of datasets that have the same summary statistics as the Datasaurus but have very different distributions (visualizations).

Start with the `datasaurus_dozen` and pipe it into the `filter` function to filter for observations where `dataset == "dino"`. Store the resulting filtered data frame as a new data frame called `dino_data`.

```{r}

dino_data <- datasaurus_dozen %>% 
  filter(dataset == "dino")
```

There is a lot going on here, so let's slow down and unpack it a bit. First, the pipe operator: `%>%`, takes what comes before it and sends it as the first argument to what comes after it. So here, we're saying `filter` the `datasaurus_dozen` data frame into only the observations where `dataset == "dino"`. Second, the assignment operator: `<-`, assigns the name `dino_data` to the filtered data frame.

Next, we need to visualize this data. We'll use the `ggplot` function for this. Its first argument is the data you're visualizing. Next we define the `aes`thetic mappings. In other words, the columns of the data that get mapped to certain aesthetic features of the plot, e.g. the `x` axis will represent the variable called `x` and the `y` axis will represent the variable called `y`. Then, we add another layer to this plot where we define which `geom`etric shapes we want to use to represent each observation in the data. In this case we want these to be points, hence `geom_point`.

```{r fig.fullwidth=TRUE}

dino_data %>% ggplot(aes(x=x, y=y)) + geom_point()

```

If this seems like a lot, it is. And we'll learn about the philosophy of building data visualizations by layering in detail next week. For now, follow along with the code that is provided.

For the second part of this exercise, we need to calculate a summary statistic: the correlation coefficient. Correlation coefficient, often referred to as $r$ in statistics, measures the linear association between two variables. You will see that some of the pairs of variables we plot do not have a linear relationship between them. This is exactly why we want to visualize first: visualize to assess the form of the relationship, and calculate $r$ only if relevant. In this case, calculating a correlation coefficient really doesn't make sense since the relationship between `x` and `y` is definitely not linear -- it's dinosaurial!

But, for illustrative purposes, let's calculate correlation coefficient between `x` and `y`. Correlation coefficients are used to measure how strong a relationship is between two variables. There are several types of correlation coefficient, but the most popular is Pearsonâ€™s. 

Start with `dino_data` and calculate a summary statistic that we will call `r` as the `cor`relation between `x` and `y`.

```{r}

dino_data %>% summarise(r = cor(x, y))

```

Let's try again with the circle dataset.  Plot `y` vs. `x` for the `circle` dataset. You can (and should) reuse code we introduced above, just replace the dataset name with the desired dataset. Then, calculate the correlation coefficient between `x` and `y` for this dataset. How does this value compare to the `r` of `dino`?

```{r}

circle <- datasaurus_dozen %>% 
  filter(dataset == "circle")


circle %>% ggplot(aes(x=x, y=y)) + geom_point()

circle %>% summarise(r = cor(x, y))

```

Finally, let's plot all datasets at once. In order to do this we will make use of faceting.

```{r}
ggplot(datasaurus_dozen, aes(x = x, y = y, color = dataset)) +
  geom_point() +
  facet_wrap(~ dataset, ncol = 3) +
 theme(legend.position = "none")
```

And we can use the `group_by` function to generate all the summary correlation coefficients.

```{r}
datasaurus_dozen %>%
  group_by(dataset) %>%
  summarize(r = cor(x, y))
```

## Other things you need to know

Even though tidyverse and ggplot are the most commonly use things in the R world right now. There are other things you should know.

One of these is two important functions: if and for. These are not tidyverse functions that use for the data cleaning and visualization but they are pretty useful, as we may want to control when and how particular parts of our code are executed. We can do that using control structures like if statements and for loops.

Control structures are blocks of code that determine how other sections of code are executed based on setting a condition. They also tell R what to do when that condition has met or has not been met.

*if* function returns two results, True or False. If the condition is true, do the things in the curly brackets

```{r}
# if(condition){
#    do something 
# }

if(datasaurus_dozen[1,2] > 50){
  print("x value is larger than 50")
}

if(datasaurus_dozen[1,2] > 60){
  print("x value is larger than 60")}

if(datasaurus_dozen[1,2] > 60){
  print("x value is larger than 60")} else{
    print("x value is not larger than 60")
  }

```

However, if statement can only take one element. It cannot take all observations

```{r, eval = FALSE}

if(datasaurus_dozen[,2] > 60){
  print("x value is larger than 60")
}

```

If you want to iterate all observations, you have to use the *for loop*. A *for loop* repeats a chunk of code multiple times for each element within an object.

```{r}
#for(iterator){
#  do someting for each iterator
#}

#we usually use i,j,k to represent the iterator


for(i in 1:10){
  print(i)
}

for(k in 1:ncol(datasaurus_dozen)){
  print(k)
}


```

Let's move to a higher level to combine them. Suppose I want to calculate how many x values are larger than 50. (There are much easier ways to do that in tidyverse but let's practice the if and for function a little bit)

```{r}
# The general logic is that I use for loop to go through each x value and if it is larger than 50, I count one, otherwise I skip it. # Hint: usually you will need a counter before the for loop.

counter = 0
for(i in 1: nrow(datasaurus_dozen)){
  if(datasaurus_dozen[i, 2] > 50){
    counter = counter + 1
  }
}
counter

```

### Try it for yourself

Now it is your turn. Write a if + for loop combination that calculate how many observations belong to the *star* dataset. Check your answer with the previous section. Even though copy and paste is an easy way to start, I do recommend to type the answer by yourself so that you can get a better understanding of coding logic.  

```{r}
counter = 0
for(i in 1: nrow(datasaurus_dozen)){
  if(datasaurus_dozen[i, 1] == "star"){
    counter = counter + 1
  }
}
counter
```

If you have more time, try to replicate the demo in previous section for the star data (or any one you are interested in). 

```{r}

star_data = datasaurus_dozen %>% 
  filter(dataset == "star")
ggplot(data = star_data, mapping = aes(x = x, y = y)) + geom_point()
star_data %>%
  summarize(r = cor(x, y))

```


[More information on if statements and for loops in R](https://www.r-bloggers.com/2019/06/how-to-use-if-else-statements-and-loops-in-r/)

## Knit your work

Click "Knit" at the top of your R Markdown document and see what happens!

## If Time: Let's play with the Code Chunk Options

Some Options:

- eval=FALSE: don't run the code

- echo=FALSE: don't show the code

- warning=FALSE: don't add R's warnings to the pdf

- message=FALSE: don't show messages from R in the pdf

- include=FALSE: don't include any R output in the document. 

- cache=FALSE: re-run all of the code every time.

How does adding these to the code chunks change the output?