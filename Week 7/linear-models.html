<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>MTH365: Introduction to Data Science</title>
    <meta charset="utf-8" />
    <meta name="author" content="Linear Models" />
    <meta name="date" content="2023-09-28" />
    <script src="libs/header-attrs-2.23/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# MTH365: Introduction to Data Science
]
.author[
### Linear Models
]
.date[
### September 28, 2023
]

---




## Agenda

Focus: Linear Regression

  + Quadratic Terms
  + Interaction Terms
  + Categorical Predictors
    - ANOVA
  + Assessing Variable Importance
    - Model Comparison

---
## Fit a model

Sometimes we want to know whether any variables are related, thus we need to fit a statistical model. 

__Statistical models__: 

There are two things we can do with fitting a model:
1. Interpretation 
2. Prediction

Sometimes we are only interested in one of them, sometimes both. They have slightly different approaches and may lead to different choice and explanation of the model.

Today's lecture we focus on interpretation and your mini-project 3 focuses on prediction. General steps for fitting a model for interpretation: 

1. Look at your research question. Identify the response variable.
2. Look at your data. Which variables may related to the response variables?
3. Fit the variables to a statistical model
4. Check the p-values to decide whether the variables is significant and interpret its meaning. 

---

## Looking for the potential correlation

__Example__: Review our NYC flight data. Is there any variable related to the arrival delay? If yes, how?

Consider a random sample of 1000 flights from NYC to Chicago in 2013.


```r
library(nycflights13)
set.seed(14)
Chicago1000 &lt;- flights %&gt;%
  filter(dest %in% c('ORD', 'MDW'), !is.na(arr_delay)) %&gt;% 
  sample_n(size=1000)
```

---
## Looking for the potential correlation

Look at the column names of the data. Which variables may be related to the arrival delay?


```r
colnames(Chicago1000)
```



```
##      [,1]             [,2]             [,3]       [,4]       
## [1,] "year"           "dep_delay"      "flight"   "distance" 
## [2,] "month"          "arr_time"       "tailnum"  "hour"     
## [3,] "day"            "sched_arr_time" "origin"   "minute"   
## [4,] "dep_time"       "arr_delay"      "dest"     "time_hour"
## [5,] "sched_dep_time" "carrier"        "air_time" ""
```
--

Maybe the time of the flights will affect the arrival delay. If yes, how? Let's check whether the variable `hour` is related to `arrival delay`. 

---
## Visualizing a Model

The next step is to use a model. A popular model we can use is a Linear Model.

A Linear Model is easy to visualize when looking at the relationship between two numerical variables


```r
Chicago1000 %&gt;% 
  ggplot(aes(x = hour, y = arr_delay)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-5-1.png" style="display: block; margin: auto;" /&gt;


---
## Try by yourself: 

Another variable that might impact `arr_delay` is `dep_delay`. Plot the linear model between departure delay and arrive delay in the sample

--


```r
Chicago1000 %&gt;% 
  ggplot(aes(x = dep_delay, y = arr_delay)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-6-1.png" style="display: block; margin: auto;" /&gt;

---
## Linear model

__Population Linear model__: The relation between the observation `\(Y\)` and independent variables `\(X_1,..., X_p\)` is formulated as 
`$$Y = \beta_0 + \beta_1X_1 + ... + \beta_pX_p + \epsilon$$`
- Y denotes the value of the response variable
- `\(\beta_0\)` denotes the population intercept 
- `\(\beta_1\)` denotes the population slope for the first predictor 
- `\(X_1\)` denotes the value of the first predictor for each observation
- `\(\epsilon\)` denotes the error

--

__Sample Linear model__: `$$Y = \hat{\beta_0} + \hat{\beta_1}X_1 + ... + \hat{\beta_p}X_p$$`

+ `\(\hat{\beta}\)` denotes an estimate of the predictors
---
## Create a Linear Model


```r
model = lm(arr_delay ~ hour, data = Chicago1000)
summary(model)
```

```
## 
## Call:
## lm(formula = arr_delay ~ hour, data = Chicago1000)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -69.14 -25.96 -10.22   8.21 389.28 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -19.5500     4.2317  -4.620 4.34e-06 ***
## hour          2.0384     0.3094   6.587 7.23e-11 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 46.13 on 998 degrees of freedom
## Multiple R-squared:  0.04167,	Adjusted R-squared:  0.04071 
## F-statistic: 43.39 on 1 and 998 DF,  p-value: 7.227e-11
```

---
## Create a Linear Model

Linear Model:

`$$\hat{y} = -19.55 + 1.8*hours$$`

**Coefficient Interpretation**: If the hour increases by one unit (one hour), then the arrival delay will increase by 1.8 units (minute). 
- Since the p value is smaller than 0.05, there is a statistical significant relationship between arrival delay and hour.
  + More on this later



---
## Adding a Quadratic Term

A population linear model with quadratic term. For example: 
`$$Y = \beta_0 + \beta_1X_1 + \beta_2X_1^2 + \epsilon$$`

Typically done if you notice a curve in the data

**Note**: If you include a higher order term in the model, you must include all lower terms
  - So, if you have `\(X^2\)`, `\(X\)` must be in the model

---
## Adding a Quadratic Term


```r
model2 = lm(arr_delay ~ hour + I(hour^2), data = Chicago1000)
summary(model2)
```

```
## 
## Call:
## lm(formula = arr_delay ~ hour + I(hour^2), data = Chicago1000)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -69.52 -25.37 -10.65   8.20 388.34 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -7.96308   12.44193  -0.640    0.522
## hour        -0.05383    2.13523  -0.025    0.980
## I(hour^2)    0.08166    0.08245   0.990    0.322
## 
## Residual standard error: 46.14 on 997 degrees of freedom
## Multiple R-squared:  0.04261,	Adjusted R-squared:  0.04069 
## F-statistic: 22.19 on 2 and 997 DF,  p-value: 3.737e-10
```

---
## Adding a Quadratic Term

Both terms' p values are larger than 0.05, indicating they do not have a statistical significant relation with arr_delay when both of them are added to the model. 

How do the linear and quadratic models compare?

We always start with a linear model and only use quadratic model if you have observed a potential quadratic trend in the EDA.

---
## Adding an Interaction Term

Interactions: used if you think two variables are related to each other

  - Must keep both variables in the model if interaction is significant 
  
Let's suppose we think there is an interaction between `hour` and `dep_delay`

---
### Adding an Interaction Term


```r
int = lm(arr_delay ~ hour + dep_delay + hour:dep_delay, 
         data = Chicago1000)
summary(int)
```

```
## 
## Call:
## lm(formula = arr_delay ~ hour + dep_delay + hour:dep_delay, data = Chicago1000)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -58.587 -11.508  -1.599   8.485 126.912 
## 
## Coefficients:
##                 Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)    -8.250380   1.792340  -4.603  4.7e-06 ***
## hour           -0.004713   0.135334  -0.035  0.97223    
## dep_delay       1.171457   0.047942  24.435  &lt; 2e-16 ***
## hour:dep_delay -0.008706   0.003054  -2.851  0.00445 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 18.92 on 996 degrees of freedom
## Multiple R-squared:  0.8392,	Adjusted R-squared:  0.8387 
## F-statistic:  1732 on 3 and 996 DF,  p-value: &lt; 2.2e-16
```


---
## Analysis of Variance (ANOVA)

What if your independent variable is categorical data?

**Analysis of variance**: used to analyze the differences among means.

--

**Example**: What about carrier? Do different carriers lead to different average arrival delay?

--

&lt;img src="linear-models_files/figure-html/unnamed-chunk-10-1.png" style="display: block; margin: auto;" /&gt;

---
## Linear Model with Categorical Explanatory

First, make sure carrier is being treated as a factor!


```r
Chicago1000$carrier = relevel(as.factor(Chicago1000$carrier), 
                              ref = "UA")
model3 = lm(arr_delay ~ carrier, data = Chicago1000)
broom::tidy(model3)
```

```
## # A tibble: 6 × 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)     4.86      2.59     1.88  0.0607 
## 2 carrier9E       4.35      6.33     0.688 0.492  
## 3 carrierAA     -10.7       3.76    -2.83  0.00468
## 4 carrierB6      20.8       7.58     2.74  0.00620
## 5 carrierMQ      12.7       5.30     2.40  0.0165 
## 6 carrierWN      12.6       4.24     2.98  0.00297
```

Carrier UA is the reference level and every other levels will be compared to it.

- For a categorical variable with `\(k\)` levels, we have `\(k-1\)` indicator variables

---
## Linear Model with Categorical Explanatory

Writing out the proper model:

`$$\hat{\text{y}} = 4.86+4.35*\text{9E}-10.7*\text{AA}+20.8*\text{B6}+12.7*\text{MQ}+12.6*\text{WN}$$`
--

For UA:
$$\hat{\text{y}} = 4.86 $$
--

For AA: 
`$$\hat{\text{y}} = 4.86+4.35*0-10.7*1+20.8*0+12.7*0+12.6*0 = 4.86-10.7$$`
`$$\hat{\text{y}} = -5.84$$`


---
## ANOVA Results

**Question**: Does at least one of the carriers have a different mean arrival delay than the others

```r
model4 = aov(arr_delay ~ carrier, data = Chicago1000)
summary(model4)
```

```
##              Df  Sum Sq Mean Sq F value  Pr(&gt;F)    
## carrier       5   95301   19060   8.932 2.6e-08 ***
## Residuals   994 2121209    2134                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

At least one of the carrier has different mean arrival delay than the others, thus carriers are significantly related to the arrival delay. 

---
## Statistical Significance

Null hypothesis significance testing (NHST):

`1.` Write a hypothesis

- Null Hypothesis: only randomness is in play
- Alternative Hypothesis: something else is happening

`2.` Calculate the test statistics

`3.` Achieve the p value based on the test statistics

`4.` Interpret the p values

**p-value**: Given the null hypothesis is true, the probability we observed the given data or more extreme.

--
  
**Example** For the airlines data, the null hypothesis is that there is no association between the predictors and flight delay, whereas the alternative hypothesis is that there is an association between the predictors and the flight delay.
---
## Statistical Significance

A p-values is computed by simulating a world in which a null hypothesis is set to be true (assuming no relationship, no randomness)
- Null hypothesis testing determines whether the sample results that you obtain are likely if you assume the null hypothesis is true for the population.

A very small p-value means the results are sufficiently improbable under the null hypothesis, so we reject the null hypothesis. 
- In other words, you can say that your results are statistically significant.

How small is “small enough”?
- Historically, when using hypothesis testing, analysts have declared results with a p-value of 0.05 or smaller as statistically significant, while values larger than 0.05 are declared non-significant.
- Statistical Level: A value `\(\alpha\)` is the probability of the study rejecting the null hypothesis, given that
the null hypothesis was assumed to be true (error).

---
## Practical Significance

Something else to consider:

- Statistical significance shows that an effect exists in a study, practical
significance shows that the effect is large enough to be meaningful in the real
world
- Hypothesis tests with small differences in values can produce very low p-values if you have large sample size or the data have low variability. Hence, differences that are trivial in the practical sense can still be highly statistically significant.


---
## ANOVA: Multiple Comparisons

**From Before**: We know that at least one of the carriers has different mean arrival delay than the others, thus carriers are significant related to the arrival delay. 


```r
model4 = aov(arr_delay ~ carrier, data = Chicago1000)
summary(model4)
```

```
##              Df  Sum Sq Mean Sq F value  Pr(&gt;F)    
## carrier       5   95301   19060   8.932 2.6e-08 ***
## Residuals   994 2121209    2134                    
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

The ANOVA test itself provides only statistical evidence of a difference, but not any statistical evidence as to which mean or means are statistically different.

Multiple comparisons conducts an analysis of all possible pairwise means. 

An adjustment is needed to account for the number of comparisons taking place (we won't get into this). 
---
## Statistical signficance: Multiple Comparisons


```r
library(multcomp)
model5 = glht(model4, linfct = mcp(carrier = "Tukey"))
summary(model5, test = adjusted("holm"))
```


```
## # A tibble: 15 × 7
##    term    contrast null.value estimate std.error statistic adj.p.value
##    &lt;chr&gt;   &lt;chr&gt;         &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
##  1 carrier 9E - UA           0   4.35        6.33    0.688   1         
##  2 carrier AA - UA           0 -10.7         3.76   -2.83    0.0514    
##  3 carrier B6 - UA           0  20.8         7.58    2.74    0.0620    
##  4 carrier MQ - UA           0  12.7         5.30    2.40    0.149     
##  5 carrier WN - UA           0  12.6         4.24    2.98    0.0356    
##  6 carrier AA - 9E           0 -15.0         6.39   -2.35    0.151     
##  7 carrier B6 - 9E           0  16.4         9.17    1.79    0.513     
##  8 carrier MQ - 9E           0   8.36        7.39    1.13    1         
##  9 carrier WN - 9E           0   8.28        6.68    1.24    1         
## 10 carrier B6 - AA           0  31.5         7.63    4.12    0.000527  
## 11 carrier MQ - AA           0  23.4         5.36    4.36    0.000203  
## 12 carrier WN - AA           0  23.3         4.33    5.38    0.00000136
## 13 carrier MQ - B6           0  -8.09        8.49   -0.952   1         
## 14 carrier WN - B6           0  -8.16        7.88   -1.04    1         
## 15 carrier WN - MQ           0  -0.0774      5.71   -0.0135  1
```

---
## Confounding

**"Correlation does not equal causation."**

What variables could be used in a model to _explain_ arrival delays?

In other words, just because there is a "statistically significant relationship" between `\(x\)` and `\(y\)`, it doesn't mean that `\(x\)` is _causing_ changes in `\(y\)`.

Other factors may affect (*confound*) the relationship between two variables.

---
## Carrier as a confounder?

__Example__: Does carrier confound the relationship between arrival delay and hour?


```r
Chicago1000 %&gt;% ggplot(aes(x = hour, y = arr_delay)) + 
  geom_point() + 
  geom_smooth(method = "lm") + 
  aes(color = carrier)
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-16-1.png" style="display: block; margin: auto;" /&gt;


---
## Multiple Linear Regression

**Until Now**: We've only had one predictor variable in our model. 

But if we suspect a variable may affect the relationship between another variable and the response (or we have multiple predictor variables of interest), we need a way to test their significance.
  - Overall F Test
  - Adjusted `\(R^2\)`
  
---
## Overall F Test

Testing for significance of all predictor variables at once 
- Null: The slope for all of the predictor variables is 0
- Alternative: The slope for at least one of the predictor variables is not 0

Asking, is the regression model containing at least one of the predictors useful in predicting the response?

---
### Overall F Test


```
## 
## Call:
## lm(formula = arr_delay ~ hour + carrier, data = Chicago1000)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -64.26 -24.12 -10.68   8.32 390.10 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) -19.4396     4.6483  -4.182 3.14e-05 ***
## hour          1.9055     0.3051   6.246 6.25e-10 ***
## carrier9E     2.8147     6.2161   0.453  0.65078    
## carrierAA    -9.9018     3.6933  -2.681  0.00746 ** 
## carrierB6    20.2891     7.4437   2.726  0.00653 ** 
## carrierMQ    11.9620     5.1993   2.301  0.02161 *  
## carrierWN    11.6865     4.1668   2.805  0.00513 ** 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 45.34 on 993 degrees of freedom
## Multiple R-squared:  0.07917,	Adjusted R-squared:  0.07361 
## F-statistic: 14.23 on 6 and 993 DF,  p-value: 1.337e-15
```

---
## Let's Return to the Quadratic Model


```r
summary(model2)
```

```
## 
## Call:
## lm(formula = arr_delay ~ hour + I(hour^2), data = Chicago1000)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -69.52 -25.37 -10.65   8.20 388.34 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept) -7.96308   12.44193  -0.640    0.522
## hour        -0.05383    2.13523  -0.025    0.980
## I(hour^2)    0.08166    0.08245   0.990    0.322
## 
## Residual standard error: 46.14 on 997 degrees of freedom
## Multiple R-squared:  0.04261,	Adjusted R-squared:  0.04069 
## F-statistic: 22.19 on 2 and 997 DF,  p-value: 3.737e-10
```

---
## Let's Return to the Quadratic Model

Overall F Test is significant -&gt; at least one of the variables is useful, even though both of their individual p-values are nonsignificant

- So one of the variables is unnecessary and should be removed
  + In this case the `\(\text{hour}^2\)` is probably unnecessary.

---
## Adjusted `\(R^2\)`

How much of the variation in our response is explained by the model

The Adjusted `\(R^2\)` does not automatically increase for additional variables
  - If a variable is not useful, Adjusted `\(R^2\)` will decrease 
  - Can use to help check variable importance
  
--

**Example**: 
- For our model with hour and carrier as explanatory variables, 7.361% of the variation in the response (arrival delay) is explained by the model 
- For our model with hour only as the explanatory variable, 4.071% of the variation in the response (arrival delay) is explained by the model

---
## AIC and BIC

Other methods to determine what variables to include in your model (model comparison).

They may not always agree as to which is the best model, so generally people choose the model based on which one is best among the fit statistics most often.

--

Other: Common Fit Statistics

- AIC: penalize the inclusion of additional variables to a model. It adds a penalty that increases the error when including additional terms. 

```r
AIC(model2)
```

```
## [1] 10506.02
```

- BIC: Stronger penalty for including additional variables to the model.


```r
BIC(model2)
```

```
## [1] 10525.65
```


---
## Multiple Linear Regression: Coefficient Interpretations

If the hour increases by one unit (one hour), then the arrival delay will increase by 1.9055 units (minute), *holding all of the other variables constant*. 


---
## Now we can create a linear model, but is it appropriate?

1. The response has a normal distribution with constant variance for each observation
2. We need to have a linear relationship (constant variance)
  - Need to do nonlinear regression if that’s the case
3. No perfect collinearity (i.e. one predictor isn’t a linear combination of another predictor in the model)
  - Focus on numerical predictor variables
  - e.g. can’t include revenue, cost, and profit in a model because profit = revenue – cost
  
---
## Assumption: Normality

Normality: assumes that any value can be attained for this response variable
- If the response has a non-normal distribution, the estimates will be biased

To check this assumption, we use a QQ-Plot
  - A scatterplot created by plotting two sets of quantiles against one another.
  - If data is normal, we should see a roughly straight line
  

```r
plot(model6, which = 2)
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-21-1.png" style="display: block; margin: auto;" /&gt;

---
## Assumption: Linearity

Look at the Residuals vs Fitted Plot
- Look to see if there are any noticeable pattern in any of the plots
- If pattern, constant variance assumption is violated


```r
plot(model6, which = 1)
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-22-1.png" style="display: block; margin: auto;" /&gt;

---
## Assumption: No Perfect Collinearity

Collinearity - a linear relationship between two variables
  - one predictor is a linear combination of another predictor in the model
  - can't include revenue, profit, cost as profit = revenue-cost


High correlation between predictor variables
  - Standard errors become inflated, which can lead to `\(\hat{\beta}\)` having the wrong sign in our predictors
  - We interpret 1 variable while holding all others constant. Holding the others constant may not be possible
  
---
## Assumption: No Perfect Collinearity

When is this an issue:
- Generally, the absolute value of a correlation above 0.8 is considered serious (caution is typically advised once you hit around 0.6)

Typically, address by removing one predictor variable at a time 
- If two variables are highly correlated, they’re both explaining the same variation in the response (redundant variable)
- Check adjusted `\(R^2\)` values


---
## Assumption: No Perfect Collinearity

Let's look at the relationship between `air_time` and `distance`


```r
library(corrplot)
```

```
## corrplot 0.92 loaded
```

```r
M &lt;- cor(Chicago1000[,c(15:16)])
corrplot(M, method = "number", type = "upper")
```

&lt;img src="linear-models_files/figure-html/unnamed-chunk-23-1.png" style="display: block; margin: auto;" /&gt;

---
## Your Turn!

Choose some other explanatory variables and try them out! Can you find a good possible model for predicting arrival delay?
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
